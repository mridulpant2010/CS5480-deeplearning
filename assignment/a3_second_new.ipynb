{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "\n",
    "class CIFAR10Dataset:\n",
    "    IMAGE_SIZE = 32\n",
    "    MEAN = (0.4914, 0.4822, 0.4465)\n",
    "    STD = (0.2470, 0.2435, 0.2616)\n",
    "\n",
    "    def __init__(self, batch_size=64, num_workers=min(2, os.cpu_count()), train_size=None, test_size=None):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.train_size = train_size\n",
    "        self.test_size = test_size\n",
    "        self.data_path = os.path.expanduser(\"~/.torchvision\")\n",
    "\n",
    "        self.class_labels = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "                             'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    def get_transforms(self, is_training=True):\n",
    "        \"\"\"Returns preprocessing transformations.\"\"\"\n",
    "        if is_training:\n",
    "            return transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((self.IMAGE_SIZE, self.IMAGE_SIZE)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomResizedCrop((self.IMAGE_SIZE, self.IMAGE_SIZE), scale=(0.8, 1.0),\n",
    "                                             ratio=(0.75, 1.33), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "                transforms.Normalize(self.MEAN, self.STD)\n",
    "            ])\n",
    "        else:\n",
    "            return transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((self.IMAGE_SIZE, self.IMAGE_SIZE)),\n",
    "                transforms.Normalize(self.MEAN, self.STD)\n",
    "            ])\n",
    "\n",
    "    def load_dataset(self, is_training=True):\n",
    "        \"\"\"Loads CIFAR-10 dataset with transformations.\"\"\"\n",
    "        dataset = CIFAR10(root=self.data_path, train=is_training, download=True,\n",
    "                          transform=self.get_transforms(is_training))\n",
    "\n",
    "        if is_training and self.train_size is not None:\n",
    "            indices = torch.randperm(len(dataset))[:self.train_size].tolist()\n",
    "            dataset = Subset(dataset, indices)\n",
    "\n",
    "        if not is_training and self.test_size is not None:\n",
    "            indices = torch.randperm(len(dataset))[:self.test_size].tolist()\n",
    "            dataset = Subset(dataset, indices)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def get_dataloaders(self):\n",
    "        \"\"\"Returns train, validation, and test DataLoaders.\"\"\"\n",
    "        train_dataset = self.load_dataset(is_training=True)\n",
    "        test_dataset = self.load_dataset(is_training=False)\n",
    "\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "\n",
    "        train_size = int(0.8 * len(train_dataset))\n",
    "        val_size = len(train_dataset) - train_size\n",
    "        train_set, val_set = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "        train_loader = DataLoader(train_set, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "        val_loader = DataLoader(val_set, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "\n",
    "        return train_loader, test_loader, val_loader, self.class_labels\n",
    "\n",
    "# Example usage:\n",
    "data_loader = CIFAR10Dataset(batch_size=128, train_size=5000, test_size=1000)\n",
    "train_loader, test_loader, val_loader, class_labels = data_loader.get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "class ViTConfig:\n",
    "    def __init__(self, config_dict):\n",
    "        for key, value in config_dict.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def display_config(self):\n",
    "        for key, value in self.__dict__.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "\n",
    "\n",
    "class PatchEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.image_size = config.image_size\n",
    "        self.patch_size = config.patch_size\n",
    "        self.num_channels = config.num_channels\n",
    "        self.num_patches = (self.image_size // self.patch_size) ** 2\n",
    "        self.hidden_size = config.hidden_size\n",
    "        \n",
    "        self.projection = nn.Conv2d(\n",
    "            self.num_channels,\n",
    "            self.hidden_size,\n",
    "            kernel_size=self.patch_size,\n",
    "            stride=self.patch_size\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.projection(x)  # (batch_size, hidden_size, num_patches_w, num_patches_h)\n",
    "        x = x.flatten(2)  # (batch_size, hidden_size, num_patches)\n",
    "        x = x.transpose(1, 2)  # (batch_size, num_patches, hidden_size)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinearEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.patch_embeddings = PatchEmbeddings(config)\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, config.hidden_size))\n",
    "        self.position_embeddings = nn.Parameter(\n",
    "            torch.zeros(1, self.patch_embeddings.num_patches + 1, config.hidden_size)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.patch_embeddings(x)  \n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)  \n",
    "        x = torch.cat((cls_tokens, x), dim=1) \n",
    "        x = x + self.position_embeddings\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class SingleAttentionHead(nn.Module):\n",
    "    def __init__(self, model_dim, head_dim, dropout_rate, use_bias=True):\n",
    "        super().__init__()\n",
    "        self.model_dim = model_dim\n",
    "        self.head_dim = head_dim\n",
    "        self.query_layer = nn.Linear(model_dim, head_dim, bias=use_bias)\n",
    "        self.key_layer = nn.Linear(model_dim, head_dim, bias=use_bias)\n",
    "        self.value_layer = nn.Linear(model_dim, head_dim, bias=use_bias)\n",
    "        self.attn_dropout_layer = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        query_tensor = self.query_layer(input_tensor)\n",
    "        key_tensor = self.key_layer(input_tensor)\n",
    "        value_tensor = self.value_layer(input_tensor)\n",
    "        attn_scores = torch.matmul(query_tensor, key_tensor.transpose(-1, -2)) / math.sqrt(self.head_dim)\n",
    "        attn_probs = nn.functional.softmax(attn_scores, dim=-1)\n",
    "        attn_probs = self.attn_dropout_layer(attn_probs)\n",
    "\n",
    "        attn_output = torch.matmul(attn_probs, value_tensor)\n",
    "        return attn_output, attn_probs\n",
    "\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, model_config):\n",
    "        super().__init__()\n",
    "        self.num_heads = model_config.num_attention_heads\n",
    "        self.head_dim = model_config.hidden_size // self.num_heads\n",
    "        self.total_head_dim = self.num_heads * self.head_dim\n",
    "        self.use_bias = model_config.qkv_bias\n",
    "        # Single projection for QKV\n",
    "        self.qkv_projection_layer = nn.Linear(model_config.hidden_size, self.total_head_dim * 3, bias=self.use_bias)\n",
    "        self.attn_dropout_layer = nn.Dropout(model_config.attention_probs_dropout_prob)\n",
    "        # Output projection\n",
    "        self.output_projection_layer = nn.Linear(self.total_head_dim,model_config.hidden_size)\n",
    "        self.output_dropout_layer = nn.Dropout(model_config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, input_tensor, return_attn_probs=False):\n",
    "        qkv_tensor = self.qkv_projection_layer(input_tensor)\n",
    "        query_tensor, key_tensor, value_tensor = torch.chunk(qkv_tensor, 3, dim=-1)\n",
    "\n",
    "        # Reshape for multi-head attention\n",
    "        batch_size, seq_length, _ = query_tensor.size()\n",
    "        query_tensor = query_tensor.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        key_tensor = key_tensor.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        value_tensor = value_tensor.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention\n",
    "        attn_scores = torch.matmul(query_tensor, key_tensor.transpose(-1, -2)) / math.sqrt(self.head_dim)\n",
    "        attn_probs = nn.functional.softmax(attn_scores, dim=-1)\n",
    "        attn_probs = self.attn_dropout_layer(attn_probs)\n",
    "        attn_output = torch.matmul(attn_probs, value_tensor)\n",
    "\n",
    "        # Reshape and project output\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_length, self.total_head_dim)\n",
    "        attn_output = self.output_projection_layer(attn_output)\n",
    "        attn_output = self.output_dropout_layer(attn_output)\n",
    "        return (attn_output, attn_probs) if return_attn_probs else (attn_output, None)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        self.fc2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.sqrt_2_over_pi = math.sqrt(2 / math.pi)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "    def gelu(self,x):\n",
    "        return 0.5 * x * (1 + torch.tanh(self.sqrt_2_over_pi * (x + 0.044715 * x ** 3)))\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, model_config):\n",
    "        super().__init__()\n",
    "        self.attention_layer = MultiHeadedAttention(model_config)\n",
    "        self.pre_norm_layer = nn.LayerNorm(model_config.hidden_size)\n",
    "        self.post_norm_layer = nn.LayerNorm(model_config.hidden_size)\n",
    "        self.feed_forward_layer = MLP(model_config)\n",
    "\n",
    "    def forward(self, input_tensor, return_attn_probs=False):\n",
    "        normalized_tensor = self.pre_norm_layer(input_tensor)\n",
    "        attention_output = self.attention_layer(normalized_tensor, output_attentions=return_attn_probs)\n",
    "\n",
    "        if return_attn_probs:\n",
    "            attention_values, attention_maps = attention_output\n",
    "        else:\n",
    "            attention_values = attention_output[0]\n",
    "        residual_tensor = input_tensor + attention_values\n",
    "        normalized_tensor = self.post_norm_layer(residual_tensor)\n",
    "        feed_forward_output = self.feed_forward_layer(normalized_tensor)\n",
    "        final_output = residual_tensor + feed_forward_output\n",
    "        return (final_output, attention_maps) if return_attn_probs else final_output\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, model_config):\n",
    "        super().__init__()\n",
    "        self.encoder_layers = nn.ModuleList([TransformerBlock(model_config) for _ in range(model_config.num_hidden_layers)])\n",
    "        \n",
    "    def forward(self, input_tensor, return_attn_probs=False):\n",
    "        attention_maps = [] if return_attn_probs else None\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            if return_attn_probs:\n",
    "                input_tensor, attn_probs = encoder_layer(input_tensor, output_attentions=True)\n",
    "                attention_maps.append(attn_probs)\n",
    "            else:\n",
    "                input_tensor = encoder_layer(input_tensor, output_attentions=False)\n",
    "        return (input_tensor, attention_maps) if return_attn_probs else input_tensor\n",
    "\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, model_config):\n",
    "        super().__init__()\n",
    "        self.model_config = model_config\n",
    "        self.embedding_layer = LinearEmbeddings(model_config)\n",
    "        self.transformer_encoder = TransformerEncoder(model_config)\n",
    "        self.output_layer = nn.Linear(model_config.hidden_size, model_config.num_classes)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._initialize_weights)\n",
    "\n",
    "    def forward(self, input_tensor, return_attentions=False):\n",
    "        embedded_features = self.embedding_layer(input_tensor)\n",
    "        \n",
    "        if return_attentions:\n",
    "            encoded_representation, attention_maps = self.transformer_encoder(\n",
    "                embedded_features, \n",
    "                output_attentions=return_attentions\n",
    "            )\n",
    "        else:\n",
    "            encoded_representation = self.transformer_encoder(embedded_features)\n",
    "\n",
    "        cls_token = encoded_representation[:, 0, :]\n",
    "        model_output = self.output_layer(cls_token)\n",
    "        \n",
    "        if return_attentions:\n",
    "            return model_output, attention_maps\n",
    "        return model_output\n",
    "\n",
    "    def _initialize_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=self.model_config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        elif isinstance(module, LinearEmbeddings):\n",
    "            # Initialize classification token and position embeddings\n",
    "            nn.init.trunc_normal_(module.cls_token, std=self.model_config.initializer_range)\n",
    "            nn.init.trunc_normal_(module.position_embeddings, std=self.model_config.initializer_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import json, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def save_experiment(experiment_name, config, model, train_losses, test_losses, accuracies, base_dir=\"experiments\"):\n",
    "    outdir = os.path.join(base_dir, experiment_name)\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    # Save the config\n",
    "    configfile = os.path.join(outdir, 'config.json')\n",
    "    with open(configfile, 'w') as f:\n",
    "        json.dump(config, f, sort_keys=True, indent=4)\n",
    "\n",
    "    # Save the metrics\n",
    "    jsonfile = os.path.join(outdir, 'metrics.json')\n",
    "    with open(jsonfile, 'w') as f:\n",
    "        data = {\n",
    "            'train_losses': train_losses,\n",
    "            'test_losses': test_losses,\n",
    "            'accuracies': accuracies,\n",
    "        }\n",
    "        json.dump(data, f, sort_keys=True, indent=4)\n",
    "\n",
    "    # Save the model\n",
    "    save_checkpoint(experiment_name, model, \"final\", base_dir=base_dir)\n",
    "\n",
    "\n",
    "def save_checkpoint(experiment_name, model, epoch, base_dir=\"experiments\"):\n",
    "    outdir = os.path.join(base_dir, experiment_name)\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    cpfile = os.path.join(outdir, f'model_{epoch}.pt')\n",
    "    torch.save(model.state_dict(), cpfile)\n",
    "\n",
    "\n",
    "def load_experiment(experiment_name, checkpoint_name=\"model_final.pt\", base_dir=\"experiments\"):\n",
    "    outdir = os.path.join(base_dir, experiment_name)\n",
    "    # Load the config\n",
    "    configfile = os.path.join(outdir, 'config.json')\n",
    "    with open(configfile, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    # Load the metrics\n",
    "    jsonfile = os.path.join(outdir, 'metrics.json')\n",
    "    with open(jsonfile, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    train_losses = data['train_losses']\n",
    "    test_losses = data['test_losses']\n",
    "    accuracies = data['accuracies']\n",
    "    # Load the model\n",
    "    model = ViTForClassfication(config)\n",
    "    cpfile = os.path.join(outdir, checkpoint_name)\n",
    "    model.load_state_dict(torch.load(cpfile))\n",
    "    return config, model, train_losses, test_losses, accuracies\n",
    "\n",
    "\n",
    "def visualize_images():\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True)\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    # Pick 30 samples randomly\n",
    "    indices = torch.randperm(len(trainset))[:30]\n",
    "    images = [np.asarray(trainset[i][0]) for i in indices]\n",
    "    labels = [trainset[i][1] for i in indices]\n",
    "    # Visualize the images using matplotlib\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    for i in range(30):\n",
    "        ax = fig.add_subplot(6, 5, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(images[i])\n",
    "        ax.set_title(classes[labels[i]])\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"\n",
    "    Enhanced trainer class for Vision Transformer with additional features:\n",
    "    - TensorBoard logging\n",
    "    - Model checkpointing\n",
    "    - Learning rate scheduling\n",
    "    - Mixed precision training\n",
    "    - Gradient accumulation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, optimizer, loss_fn, exp_name, device, config=None):\n",
    "        self.model = model.to(device)\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.exp_name = exp_name\n",
    "        self.device = device\n",
    "        self.config = config\n",
    "        \n",
    "        # Create experiment directory\n",
    "        self.timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self.exp_dir = os.path.join(\"experiments\", f\"{exp_name}_{self.timestamp}\")\n",
    "        os.makedirs(self.exp_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize TensorBoard writer\n",
    "        self.writer = SummaryWriter(log_dir=os.path.join(self.exp_dir, \"logs\"))\n",
    "        \n",
    "        # Training metrics\n",
    "        self.best_accuracy = 0.0\n",
    "        self.train_losses = []\n",
    "        self.test_losses = []\n",
    "        self.accuracies = []\n",
    "        \n",
    "        # Automatic mixed precision\n",
    "        self.scaler = torch.cuda.amp.GradScaler(enabled=(device == 'cuda'))\n",
    "\n",
    "    def train(self, trainloader, testloader, epochs, \n",
    "              save_model_every_n_epochs=0, grad_accum_steps=1,\n",
    "              scheduler=None, early_stopping_patience=None):\n",
    "        \"\"\"\n",
    "        Train the model for the specified number of epochs.\n",
    "        \n",
    "        Args:\n",
    "            trainloader: DataLoader for training data\n",
    "            testloader: DataLoader for validation data\n",
    "            epochs: Number of training epochs\n",
    "            save_model_every_n_epochs: Save checkpoint every n epochs (0 to disable)\n",
    "            grad_accum_steps: Number of gradient accumulation steps\n",
    "            scheduler: Learning rate scheduler\n",
    "            early_stopping_patience: Stop training if validation accuracy doesn't improve for n epochs\n",
    "        \"\"\"\n",
    "        early_stop_counter = 0\n",
    "        \n",
    "        for epoch in range(1, epochs + 1):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Train for one epoch\n",
    "            train_loss = self.train_epoch(trainloader, grad_accum_steps)\n",
    "            \n",
    "            # Evaluate on validation set\n",
    "            accuracy, test_loss = self.evaluate(testloader)\n",
    "            \n",
    "            # Update learning rate scheduler if provided\n",
    "            if scheduler:\n",
    "                if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    scheduler.step(test_loss)\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "            \n",
    "            # Record metrics\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.test_losses.append(test_loss)\n",
    "            self.accuracies.append(accuracy)\n",
    "            \n",
    "            # Log to TensorBoard\n",
    "            self.writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "            self.writer.add_scalar('Loss/test', test_loss, epoch)\n",
    "            self.writer.add_scalar('Accuracy/test', accuracy, epoch)\n",
    "            \n",
    "            # Print epoch summary\n",
    "            epoch_time = time.time() - start_time\n",
    "            lr = self.optimizer.param_groups[0]['lr']\n",
    "            print(f\"Epoch: {epoch}/{epochs} | Time: {epoch_time:.2f}s | LR: {lr:.2e} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | \"\n",
    "                  f\"Accuracy: {accuracy:.4f}\")\n",
    "            \n",
    "            # Save checkpoint\n",
    "            if save_model_every_n_epochs > 0 and epoch % save_model_every_n_epochs == 0:\n",
    "                self._save_checkpoint(epoch, is_best=False)\n",
    "            \n",
    "            # Save best model\n",
    "            if accuracy > self.best_accuracy:\n",
    "                self.best_accuracy = accuracy\n",
    "                self._save_checkpoint(epoch, is_best=True)\n",
    "                early_stop_counter = 0\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "            \n",
    "            # Early stopping\n",
    "            if early_stopping_patience and early_stop_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping at epoch {epoch} as accuracy didn't improve for {early_stopping_patience} epochs\")\n",
    "                break\n",
    "        \n",
    "        # Final save\n",
    "        self._save_checkpoint(epochs, is_best=False)\n",
    "        self._save_experiment()\n",
    "        self.writer.close()\n",
    "\n",
    "    def train_epoch(self, trainloader, grad_accum_steps=1):\n",
    "        \"\"\"\n",
    "        Train the model for one epoch with optional gradient accumulation.\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for step, batch in enumerate(trainloader, 1):\n",
    "            # Move batch to device\n",
    "            images, labels = batch\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with torch.cuda.amp.autocast(enabled=(self.device == 'cuda')):\n",
    "                outputs = self.model(images)\n",
    "                loss = self.loss_fn(outputs, labels) / grad_accum_steps\n",
    "            \n",
    "            # Backward pass with gradient scaling\n",
    "            self.scaler.scale(loss).backward()\n",
    "            \n",
    "            # Gradient accumulation\n",
    "            if step % grad_accum_steps == 0:\n",
    "                # Update weights\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "                self.optimizer.zero_grad()\n",
    "            \n",
    "            # Update metrics\n",
    "            batch_size = images.size(0)\n",
    "            total_loss += loss.item() * batch_size * grad_accum_steps\n",
    "            total_samples += batch_size\n",
    "        \n",
    "        return total_loss / total_samples\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, testloader):\n",
    "        \"\"\"\n",
    "        Evaluate the model on the test/validation set.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for batch in testloader:\n",
    "            images, labels = batch\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            with torch.cuda.amp.autocast(enabled=(self.device == 'cuda')):\n",
    "                outputs = self.model(images)\n",
    "                loss = self.loss_fn(outputs, labels)\n",
    "            \n",
    "            # Update metrics\n",
    "            batch_size = images.size(0)\n",
    "            total_loss += loss.item() * batch_size\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total_samples += batch_size\n",
    "        \n",
    "        accuracy = correct / total_samples\n",
    "        avg_loss = total_loss / total_samples\n",
    "        return accuracy, avg_loss\n",
    "\n",
    "    def _save_checkpoint(self, epoch, is_best=False):\n",
    "        \"\"\"Save model checkpoint.\"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'train_losses': self.train_losses,\n",
    "            'test_losses': self.test_losses,\n",
    "            'accuracies': self.accuracies,\n",
    "            'best_accuracy': self.best_accuracy,\n",
    "            'config': self.config\n",
    "        }\n",
    "        \n",
    "        if is_best:\n",
    "            filename = os.path.join(self.exp_dir, \"best_model.pth\")\n",
    "        else:\n",
    "            filename = os.path.join(self.exp_dir, f\"checkpoint_epoch_{epoch}.pth\")\n",
    "        \n",
    "        torch.save(checkpoint, filename)\n",
    "        print(f\"Saved {'best ' if is_best else ''}checkpoint to {filename}\")\n",
    "\n",
    "    def _save_experiment(self):\n",
    "        \"\"\"Save experiment results and configuration.\"\"\"\n",
    "        experiment = {\n",
    "            'config': self.config,\n",
    "            'train_losses': self.train_losses,\n",
    "            'test_losses': self.test_losses,\n",
    "            'accuracies': self.accuracies,\n",
    "            'best_accuracy': self.best_accuracy,\n",
    "            'timestamp': self.timestamp\n",
    "        }\n",
    "        \n",
    "        filename = os.path.join(self.exp_dir, \"experiment_results.pth\")\n",
    "        torch.save(experiment, filename)\n",
    "        print(f\"Saved experiment results to {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pantm\\AppData\\Local\\Temp\\ipykernel_15712\\1552486276.py:117: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=(device == 'cuda'))\n",
      "C:\\Users\\pantm\\AppData\\Local\\Temp\\ipykernel_15712\\1552486276.py:205: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(self.device == 'cuda')):\n",
      "C:\\Users\\pantm\\AppData\\Local\\Temp\\ipykernel_15712\\1552486276.py:241: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(self.device == 'cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50 | Time: 33.83s | LR: 3.00e-04 | Train Loss: 2.2097 | Test Loss: 2.1430 | Accuracy: 0.1800\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 2/50 | Time: 35.60s | LR: 2.99e-04 | Train Loss: 2.0728 | Test Loss: 2.0547 | Accuracy: 0.2500\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 3/50 | Time: 30.65s | LR: 2.97e-04 | Train Loss: 2.0078 | Test Loss: 1.9927 | Accuracy: 0.2700\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 4/50 | Time: 33.87s | LR: 2.95e-04 | Train Loss: 1.9481 | Test Loss: 1.9755 | Accuracy: 0.2670\n",
      "Epoch: 5/50 | Time: 34.03s | LR: 2.93e-04 | Train Loss: 1.9221 | Test Loss: 1.9043 | Accuracy: 0.3150\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 6/50 | Time: 33.69s | LR: 2.89e-04 | Train Loss: 1.8734 | Test Loss: 1.8901 | Accuracy: 0.3320\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 7/50 | Time: 33.03s | LR: 2.86e-04 | Train Loss: 1.8466 | Test Loss: 1.8390 | Accuracy: 0.3460\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 8/50 | Time: 36.10s | LR: 2.81e-04 | Train Loss: 1.8259 | Test Loss: 1.8356 | Accuracy: 0.3520\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 9/50 | Time: 35.70s | LR: 2.77e-04 | Train Loss: 1.7958 | Test Loss: 1.8191 | Accuracy: 0.3520\n",
      "Epoch: 10/50 | Time: 34.22s | LR: 2.71e-04 | Train Loss: 1.7722 | Test Loss: 1.7816 | Accuracy: 0.3620\n",
      "Saved checkpoint to experiments\\vit_cifar10_896_20250402_202045\\checkpoint_epoch_10.pth\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 11/50 | Time: 33.35s | LR: 2.66e-04 | Train Loss: 1.7689 | Test Loss: 1.7954 | Accuracy: 0.3580\n",
      "Epoch: 12/50 | Time: 36.61s | LR: 2.59e-04 | Train Loss: 1.7707 | Test Loss: 1.8002 | Accuracy: 0.3510\n",
      "Epoch: 13/50 | Time: 39.47s | LR: 2.53e-04 | Train Loss: 1.7551 | Test Loss: 1.7627 | Accuracy: 0.3690\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 14/50 | Time: 33.02s | LR: 2.46e-04 | Train Loss: 1.7161 | Test Loss: 1.7400 | Accuracy: 0.3780\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 15/50 | Time: 27.95s | LR: 2.38e-04 | Train Loss: 1.7133 | Test Loss: 1.7322 | Accuracy: 0.3870\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 16/50 | Time: 28.12s | LR: 2.30e-04 | Train Loss: 1.6997 | Test Loss: 1.7263 | Accuracy: 0.3930\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 17/50 | Time: 26.80s | LR: 2.22e-04 | Train Loss: 1.7027 | Test Loss: 1.7550 | Accuracy: 0.3920\n",
      "Epoch: 18/50 | Time: 25.59s | LR: 2.14e-04 | Train Loss: 1.6905 | Test Loss: 1.7380 | Accuracy: 0.3720\n",
      "Epoch: 19/50 | Time: 28.58s | LR: 2.05e-04 | Train Loss: 1.6671 | Test Loss: 1.7029 | Accuracy: 0.3990\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 20/50 | Time: 28.90s | LR: 1.96e-04 | Train Loss: 1.6677 | Test Loss: 1.7155 | Accuracy: 0.3990\n",
      "Saved checkpoint to experiments\\vit_cifar10_896_20250402_202045\\checkpoint_epoch_20.pth\n",
      "Epoch: 21/50 | Time: 27.53s | LR: 1.87e-04 | Train Loss: 1.6601 | Test Loss: 1.6843 | Accuracy: 0.4040\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 22/50 | Time: 27.75s | LR: 1.78e-04 | Train Loss: 1.6418 | Test Loss: 1.6921 | Accuracy: 0.4130\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 23/50 | Time: 27.68s | LR: 1.69e-04 | Train Loss: 1.6307 | Test Loss: 1.6871 | Accuracy: 0.3980\n",
      "Epoch: 24/50 | Time: 27.21s | LR: 1.59e-04 | Train Loss: 1.6271 | Test Loss: 1.7092 | Accuracy: 0.3930\n",
      "Epoch: 25/50 | Time: 29.71s | LR: 1.50e-04 | Train Loss: 1.6070 | Test Loss: 1.6932 | Accuracy: 0.4010\n",
      "Epoch: 26/50 | Time: 40.59s | LR: 1.41e-04 | Train Loss: 1.5956 | Test Loss: 1.6642 | Accuracy: 0.4150\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 27/50 | Time: 37.42s | LR: 1.31e-04 | Train Loss: 1.5947 | Test Loss: 1.6791 | Accuracy: 0.3970\n",
      "Epoch: 28/50 | Time: 29.77s | LR: 1.22e-04 | Train Loss: 1.6034 | Test Loss: 1.6732 | Accuracy: 0.4090\n",
      "Epoch: 29/50 | Time: 28.13s | LR: 1.13e-04 | Train Loss: 1.5867 | Test Loss: 1.6760 | Accuracy: 0.3990\n",
      "Epoch: 30/50 | Time: 29.07s | LR: 1.04e-04 | Train Loss: 1.5791 | Test Loss: 1.6619 | Accuracy: 0.4270\n",
      "Saved checkpoint to experiments\\vit_cifar10_896_20250402_202045\\checkpoint_epoch_30.pth\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 31/50 | Time: 38.09s | LR: 9.48e-05 | Train Loss: 1.5628 | Test Loss: 1.6495 | Accuracy: 0.4240\n",
      "Epoch: 32/50 | Time: 38.88s | LR: 8.61e-05 | Train Loss: 1.5620 | Test Loss: 1.6610 | Accuracy: 0.4160\n",
      "Epoch: 33/50 | Time: 38.47s | LR: 7.77e-05 | Train Loss: 1.5610 | Test Loss: 1.6351 | Accuracy: 0.4240\n",
      "Epoch: 34/50 | Time: 37.45s | LR: 6.96e-05 | Train Loss: 1.5458 | Test Loss: 1.6393 | Accuracy: 0.4220\n",
      "Epoch: 35/50 | Time: 30.16s | LR: 6.18e-05 | Train Loss: 1.5379 | Test Loss: 1.6284 | Accuracy: 0.4280\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 36/50 | Time: 28.19s | LR: 5.44e-05 | Train Loss: 1.5407 | Test Loss: 1.6258 | Accuracy: 0.4230\n",
      "Epoch: 37/50 | Time: 28.73s | LR: 4.73e-05 | Train Loss: 1.5300 | Test Loss: 1.6232 | Accuracy: 0.4320\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 38/50 | Time: 27.18s | LR: 4.07e-05 | Train Loss: 1.5258 | Test Loss: 1.6249 | Accuracy: 0.4240\n",
      "Epoch: 39/50 | Time: 30.24s | LR: 3.44e-05 | Train Loss: 1.5201 | Test Loss: 1.6185 | Accuracy: 0.4220\n",
      "Epoch: 40/50 | Time: 29.25s | LR: 2.86e-05 | Train Loss: 1.5263 | Test Loss: 1.6165 | Accuracy: 0.4240\n",
      "Saved checkpoint to experiments\\vit_cifar10_896_20250402_202045\\checkpoint_epoch_40.pth\n",
      "Epoch: 41/50 | Time: 27.90s | LR: 2.34e-05 | Train Loss: 1.5237 | Test Loss: 1.6114 | Accuracy: 0.4330\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_202045\\best_model.pth\n",
      "Epoch: 42/50 | Time: 28.24s | LR: 1.86e-05 | Train Loss: 1.5063 | Test Loss: 1.6150 | Accuracy: 0.4300\n",
      "Epoch: 43/50 | Time: 28.93s | LR: 1.43e-05 | Train Loss: 1.5059 | Test Loss: 1.6122 | Accuracy: 0.4200\n",
      "Epoch: 44/50 | Time: 32.78s | LR: 1.05e-05 | Train Loss: 1.5058 | Test Loss: 1.6084 | Accuracy: 0.4250\n",
      "Epoch: 45/50 | Time: 28.91s | LR: 7.34e-06 | Train Loss: 1.5096 | Test Loss: 1.6078 | Accuracy: 0.4230\n",
      "Epoch: 46/50 | Time: 26.65s | LR: 4.71e-06 | Train Loss: 1.5055 | Test Loss: 1.6107 | Accuracy: 0.4230\n",
      "Epoch: 47/50 | Time: 29.42s | LR: 2.66e-06 | Train Loss: 1.5035 | Test Loss: 1.6096 | Accuracy: 0.4260\n",
      "Epoch: 48/50 | Time: 30.09s | LR: 1.18e-06 | Train Loss: 1.4997 | Test Loss: 1.6096 | Accuracy: 0.4240\n",
      "Epoch: 49/50 | Time: 27.80s | LR: 2.96e-07 | Train Loss: 1.4994 | Test Loss: 1.6094 | Accuracy: 0.4240\n",
      "Early stopping at epoch 49 as accuracy didn't improve for 8 epochs\n",
      "Saved checkpoint to experiments\\vit_cifar10_896_20250402_202045\\checkpoint_epoch_50.pth\n",
      "Saved experiment results to experiments\\vit_cifar10_896_20250402_202045\\experiment_results.pth\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    # Architecture (Lightweight)\n",
    "    \"patch_size\": 8,           # 32x32 → 4x4 patches (16 total) - reduces sequence length\n",
    "    \"hidden_size\": 96,         # Smaller than GPU config (originally 128)\n",
    "    \"num_hidden_layers\": 4,    # Reduced from 6 for faster CPU training\n",
    "    \"num_attention_heads\": 3,  # Must divide hidden_size (96/3=32)\n",
    "    \"intermediate_size\": 384,  # 4*hidden_size\n",
    "\n",
    "      \n",
    "    # Regularization (Critical for CPU training)\n",
    "    \"hidden_dropout_prob\": 0.05,\n",
    "    \"attention_probs_dropout_prob\": 0.05,\n",
    "    \n",
    "    # Training\n",
    "    \"initializer_range\": 0.02,\n",
    "    \"image_size\": 32,\n",
    "    \"num_classes\": 10,\n",
    "    \"num_channels\": 3,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "\n",
    "from torch.optim.lr_scheduler import SequentialLR,LinearLR,CosineAnnealingLR\n",
    "# Create model\n",
    "model = ViTClassification(ViTConfig(config))\n",
    "\n",
    "# Create optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    exp_name=\"vit_cifar10_896\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# warmup_epochs = 10\n",
    "# scheduler = SequentialLR(\n",
    "#     optimizer,\n",
    "#     schedulers=[\n",
    "#         LinearLR(optimizer, start_factor=0.01, total_iters=warmup_epochs),\n",
    "#         CosineAnnealingLR(optimizer, T_max=90, eta_min=1e-5)  # T_max = epochs - warmup\n",
    "#     ],\n",
    "#     milestones=[warmup_epochs]\n",
    "# )\n",
    "\n",
    "# Train the model\n",
    "trainer.train(\n",
    "    trainloader=train_loader,\n",
    "    testloader=test_loader,\n",
    "    epochs=50,\n",
    "    save_model_every_n_epochs=10,\n",
    "    grad_accum_steps=2,\n",
    "    scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50),\n",
    "    early_stopping_patience=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pantm\\AppData\\Local\\Temp\\ipykernel_15712\\1552486276.py:117: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=(device == 'cuda'))\n",
      "C:\\Users\\pantm\\AppData\\Local\\Temp\\ipykernel_15712\\1552486276.py:205: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(self.device == 'cuda')):\n",
      "C:\\Users\\pantm\\AppData\\Local\\Temp\\ipykernel_15712\\1552486276.py:241: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(self.device == 'cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100 | Time: 29.33s | LR: 3.00e-04 | Train Loss: 2.1129 | Test Loss: 2.0503 | Accuracy: 0.2490\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_194930\\best_model.pth\n",
      "Epoch: 2/100 | Time: 25.08s | LR: 2.99e-04 | Train Loss: 2.0216 | Test Loss: 1.9860 | Accuracy: 0.2970\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_194930\\best_model.pth\n",
      "Epoch: 3/100 | Time: 30.01s | LR: 2.97e-04 | Train Loss: 1.9616 | Test Loss: 1.9251 | Accuracy: 0.3350\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_194930\\best_model.pth\n",
      "Epoch: 4/100 | Time: 30.38s | LR: 2.95e-04 | Train Loss: 1.9213 | Test Loss: 1.9029 | Accuracy: 0.3230\n",
      "Epoch: 5/100 | Time: 29.33s | LR: 2.93e-04 | Train Loss: 1.8665 | Test Loss: 1.8450 | Accuracy: 0.3590\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_194930\\best_model.pth\n",
      "Epoch: 6/100 | Time: 24.62s | LR: 2.89e-04 | Train Loss: 1.8250 | Test Loss: 1.8232 | Accuracy: 0.3570\n",
      "Epoch: 7/100 | Time: 26.91s | LR: 2.86e-04 | Train Loss: 1.7870 | Test Loss: 1.7744 | Accuracy: 0.3880\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_194930\\best_model.pth\n",
      "Epoch: 8/100 | Time: 28.83s | LR: 2.81e-04 | Train Loss: 1.7619 | Test Loss: 1.7633 | Accuracy: 0.3630\n",
      "Epoch: 9/100 | Time: 29.49s | LR: 2.77e-04 | Train Loss: 1.7407 | Test Loss: 1.7629 | Accuracy: 0.3560\n",
      "Epoch: 10/100 | Time: 29.23s | LR: 2.71e-04 | Train Loss: 1.7191 | Test Loss: 1.7181 | Accuracy: 0.3870\n",
      "Saved checkpoint to experiments\\vit_cifar10_896_20250402_194930\\checkpoint_epoch_10.pth\n",
      "Epoch: 11/100 | Time: 27.55s | LR: 2.66e-04 | Train Loss: 1.7017 | Test Loss: 1.7196 | Accuracy: 0.3840\n",
      "Epoch: 12/100 | Time: 29.62s | LR: 2.59e-04 | Train Loss: 1.6759 | Test Loss: 1.7154 | Accuracy: 0.3830\n",
      "Epoch: 13/100 | Time: 27.74s | LR: 2.53e-04 | Train Loss: 1.6518 | Test Loss: 1.6843 | Accuracy: 0.4030\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_194930\\best_model.pth\n",
      "Epoch: 14/100 | Time: 24.15s | LR: 2.46e-04 | Train Loss: 1.6226 | Test Loss: 1.7263 | Accuracy: 0.3780\n",
      "Epoch: 15/100 | Time: 23.39s | LR: 2.38e-04 | Train Loss: 1.6495 | Test Loss: 1.6486 | Accuracy: 0.4160\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_194930\\best_model.pth\n",
      "Epoch: 16/100 | Time: 25.62s | LR: 2.30e-04 | Train Loss: 1.6046 | Test Loss: 1.6702 | Accuracy: 0.4000\n",
      "Epoch: 17/100 | Time: 23.63s | LR: 2.22e-04 | Train Loss: 1.5720 | Test Loss: 1.6440 | Accuracy: 0.4140\n",
      "Epoch: 18/100 | Time: 26.06s | LR: 2.14e-04 | Train Loss: 1.5686 | Test Loss: 1.6234 | Accuracy: 0.4230\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_194930\\best_model.pth\n",
      "Epoch: 19/100 | Time: 26.82s | LR: 2.05e-04 | Train Loss: 1.5365 | Test Loss: 1.5798 | Accuracy: 0.4440\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_194930\\best_model.pth\n",
      "Epoch: 20/100 | Time: 24.77s | LR: 1.96e-04 | Train Loss: 1.5129 | Test Loss: 1.6162 | Accuracy: 0.4190\n",
      "Saved checkpoint to experiments\\vit_cifar10_896_20250402_194930\\checkpoint_epoch_20.pth\n",
      "Epoch: 21/100 | Time: 26.16s | LR: 1.87e-04 | Train Loss: 1.5018 | Test Loss: 1.5680 | Accuracy: 0.4220\n",
      "Epoch: 22/100 | Time: 30.12s | LR: 1.78e-04 | Train Loss: 1.4745 | Test Loss: 1.5873 | Accuracy: 0.4230\n",
      "Epoch: 23/100 | Time: 29.51s | LR: 1.69e-04 | Train Loss: 1.4669 | Test Loss: 1.5600 | Accuracy: 0.4540\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_194930\\best_model.pth\n",
      "Epoch: 24/100 | Time: 26.49s | LR: 1.59e-04 | Train Loss: 1.4478 | Test Loss: 1.5632 | Accuracy: 0.4430\n",
      "Epoch: 25/100 | Time: 24.88s | LR: 1.50e-04 | Train Loss: 1.4289 | Test Loss: 1.5606 | Accuracy: 0.4450\n",
      "Epoch: 26/100 | Time: 26.70s | LR: 1.41e-04 | Train Loss: 1.4361 | Test Loss: 1.5734 | Accuracy: 0.4350\n",
      "Epoch: 27/100 | Time: 28.89s | LR: 1.31e-04 | Train Loss: 1.4087 | Test Loss: 1.5301 | Accuracy: 0.4560\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_194930\\best_model.pth\n",
      "Epoch: 28/100 | Time: 27.68s | LR: 1.22e-04 | Train Loss: 1.3885 | Test Loss: 1.5329 | Accuracy: 0.4490\n",
      "Epoch: 29/100 | Time: 28.80s | LR: 1.13e-04 | Train Loss: 1.3751 | Test Loss: 1.5375 | Accuracy: 0.4490\n",
      "Epoch: 30/100 | Time: 29.19s | LR: 1.04e-04 | Train Loss: 1.3632 | Test Loss: 1.5281 | Accuracy: 0.4650\n",
      "Saved checkpoint to experiments\\vit_cifar10_896_20250402_194930\\checkpoint_epoch_30.pth\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_194930\\best_model.pth\n",
      "Epoch: 31/100 | Time: 26.94s | LR: 9.48e-05 | Train Loss: 1.3439 | Test Loss: 1.5092 | Accuracy: 0.4670\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_194930\\best_model.pth\n",
      "Epoch: 32/100 | Time: 25.11s | LR: 8.61e-05 | Train Loss: 1.3281 | Test Loss: 1.4996 | Accuracy: 0.4720\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_194930\\best_model.pth\n",
      "Epoch: 33/100 | Time: 26.36s | LR: 7.77e-05 | Train Loss: 1.3228 | Test Loss: 1.5148 | Accuracy: 0.4640\n",
      "Epoch: 34/100 | Time: 29.51s | LR: 6.96e-05 | Train Loss: 1.3096 | Test Loss: 1.5056 | Accuracy: 0.4590\n",
      "Epoch: 35/100 | Time: 30.01s | LR: 6.18e-05 | Train Loss: 1.3105 | Test Loss: 1.5035 | Accuracy: 0.4670\n",
      "Epoch: 36/100 | Time: 28.55s | LR: 5.44e-05 | Train Loss: 1.2800 | Test Loss: 1.4982 | Accuracy: 0.4670\n",
      "Epoch: 37/100 | Time: 28.11s | LR: 4.73e-05 | Train Loss: 1.2693 | Test Loss: 1.4745 | Accuracy: 0.4770\n",
      "Saved best checkpoint to experiments\\vit_cifar10_896_20250402_194930\\best_model.pth\n",
      "Epoch: 38/100 | Time: 28.44s | LR: 4.07e-05 | Train Loss: 1.2585 | Test Loss: 1.4802 | Accuracy: 0.4670\n",
      "Epoch: 39/100 | Time: 26.47s | LR: 3.44e-05 | Train Loss: 1.2668 | Test Loss: 1.4800 | Accuracy: 0.4770\n",
      "Epoch: 40/100 | Time: 28.78s | LR: 2.86e-05 | Train Loss: 1.2571 | Test Loss: 1.4825 | Accuracy: 0.4730\n",
      "Saved checkpoint to experiments\\vit_cifar10_896_20250402_194930\\checkpoint_epoch_40.pth\n",
      "Epoch: 41/100 | Time: 26.55s | LR: 2.34e-05 | Train Loss: 1.2483 | Test Loss: 1.4770 | Accuracy: 0.4710\n",
      "Epoch: 42/100 | Time: 28.96s | LR: 1.86e-05 | Train Loss: 1.2370 | Test Loss: 1.4852 | Accuracy: 0.4770\n",
      "Epoch: 43/100 | Time: 27.69s | LR: 1.43e-05 | Train Loss: 1.2262 | Test Loss: 1.4775 | Accuracy: 0.4750\n",
      "Epoch: 44/100 | Time: 27.47s | LR: 1.05e-05 | Train Loss: 1.2297 | Test Loss: 1.4777 | Accuracy: 0.4740\n",
      "Epoch: 45/100 | Time: 24.91s | LR: 7.34e-06 | Train Loss: 1.2133 | Test Loss: 1.4757 | Accuracy: 0.4760\n",
      "Early stopping at epoch 45 as accuracy didn't improve for 8 epochs\n",
      "Saved checkpoint to experiments\\vit_cifar10_896_20250402_194930\\checkpoint_epoch_100.pth\n",
      "Saved experiment results to experiments\\vit_cifar10_896_20250402_194930\\experiment_results.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = {\n",
    "    # Architecture (Lightweight)\n",
    "    \"patch_size\": 8,           # 32x32 → 4x4 patches (16 total) - reduces sequence length\n",
    "    \"hidden_size\": 96,         # Smaller than GPU config (originally 128)\n",
    "    \"num_hidden_layers\": 4,    # Reduced from 6 for faster CPU training\n",
    "    \"num_attention_heads\": 3,  # Must divide hidden_size (96/3=32)\n",
    "    \"intermediate_size\": 384,  # 4*hidden_size\n",
    "\n",
    "      \n",
    "    # Regularization (Critical for CPU training)\n",
    "    \"hidden_dropout_prob\": 0.0,\n",
    "    \"attention_probs_dropout_prob\": 0.0,\n",
    "    \n",
    "    # Training\n",
    "    \"initializer_range\": 0.02,\n",
    "    \"image_size\": 32,\n",
    "    \"num_classes\": 10,\n",
    "    \"num_channels\": 3,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "\n",
    "from torch.optim.lr_scheduler import SequentialLR,LinearLR,CosineAnnealingLR\n",
    "# Create model\n",
    "model = ViTClassification(ViTConfig(config))\n",
    "#print(torchinfo.summary(model, (1, 3, 32, 32)))\n",
    "# Create optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01,betas=(0.9,0.999))\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    exp_name=\"vit_cifar10_896\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# warmup_epochs = 10\n",
    "# scheduler = SequentialLR(\n",
    "#     optimizer,\n",
    "#     schedulers=[\n",
    "#         LinearLR(optimizer, start_factor=0.01, total_iters=warmup_epochs),\n",
    "#         CosineAnnealingLR(optimizer, T_max=90, eta_min=1e-5)  # T_max = epochs - warmup\n",
    "#     ],\n",
    "#     milestones=[warmup_epochs]\n",
    "# )\n",
    "\n",
    "# Train the model\n",
    "trainer.train(\n",
    "    trainloader=train_loader,\n",
    "    testloader=test_loader,\n",
    "    epochs=100,\n",
    "    save_model_every_n_epochs=10,\n",
    "    grad_accum_steps=2,\n",
    "    scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50),\n",
    "    early_stopping_patience=8\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
